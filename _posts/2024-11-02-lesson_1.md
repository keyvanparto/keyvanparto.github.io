---
layout: post
title: "Lesson 1: Building a Learning Machine"
description: "An overview of machine learning: predicting the future by learning from the past"
media_subpath: /img/lesson_1
image:
  path: /building_a_learning_machine.png
date: 2024-11-02
math: true
categories: [Machine Learning, en]
tags: [machine-learning, introduction, learning-algorithms, data-science, ai-basics, model-training, ml-theory]     # TAG names should always be lowercase
---

{% include disclaimer.html %}

In the real world, there are numerous complex phenomena that escape our detailed understanding. Often, we don’t know exactly how they work internally, but we can observe their input variables and final outcomes: these two measures are our data. And the more data we have, the happier we are.

Ultimately, whether it’s understanding the financial market or our chances of survival, what we humans really want is to predict the future.

<h2 id="world-phenomena"><span class="me-2">Formalizing Real-World Phenomena</span><a href="#world-phenomena" class="anchor text-muted"></a></h2>

<br><br>

![Light mode only](/sistema.png){: .light }
![Dark mode only](/sistemadark.png){: .dark }
_A highly simplified model of many real-world complex phenomena_

<br>

We can identify:

1. **An unknown system**: $$ S $$ is a complex system whose rules or inner mechanisms are unknown—a sort of "black box." We don’t know exactly what algorithms, logic, or rules govern it, and we have no way to "look inside" to uncover them. However, we do know that $$ S $$ produces certain observable results.

2. **Measurable variables**: $$ x $$ represents the data we can easily collect. These inputs might include observations we already have or that we can obtain at a low cost, such as a customer’s transaction history, weather data for a region, or routine medical exam results. In other words, $$ x $$ is the set of available and observable data from which we can begin to explore the system.

3. **Target variables**: $$ y $$ represents what we would like to predict or understand. Often, however, measuring $$ y $$ can be challenging or expensive. $$ y $$ might be a value that will only become available in the future (like a stock price one month from now) or something that is complex and costly to determine right now (like the exact wear and tear of all components in a vehicle). If we wait long enough, sometimes $$ y $$ becomes observable — for instance, we will know which part of a car will break down when it actually fails.

Therefore, $$ x $$ and $$ y $$ represent our historical data.

<blockquote class="prompt-warning">  
  <p>It is crucial to emphasize that there is no causal relationship between \( x \) and \( y \) (\( x \) does not necessarily generate a specific \( y \)), but rather, there is only a <strong>correlation</strong> between them.</p>  
</blockquote>

<h2 id="learning-machine"><span class="me-2">Learning Machine</span><a href="#learning-machine" class="anchor text-muted"></a></h2>

Our goal is to build a learning machine that, using historical data (i.e., the past), can reliably predict the future. Given an input $$ x $$, perhaps one never seen before, we want to produce an estimate $$ \hat{y} $$ that is as close as possible to the true value of $$ y $$ in the original system.

![Light mode only](/learningmachine.png){: .light }
![Dark mode only](/learningmachinedark.png){: .dark }
_The closest we get to predicting the future_

In other words, we are trying to predict the future. But when can we truly predict the future?

<blockquote class="prompt-info">  
  <p>We can predict the future only when it is similar to the past.</p>  
</blockquote>

We must define *similar* and what constitutes a good approximation between $$ \hat{y} $$ and $$ y $$.

But is it possible to predict the future exactly, even with an oracle providing all the historical data we need?  

The answer is no.  

Perfect predictions are impossible, and the primary reason is **noise**.

<h3 id="noise"><span class="me-2">Noise</span><a href="#noise" class="anchor text-muted"></a></h3>

There are mainly two sources of noise that affect predictions:

1. **Noise due to measurement errors**: This type of noise occurs because of inaccuracies in instruments or measurement techniques. Whenever we collect data, especially in the real world, there is always an error component introducing unwanted variations in the observed values.

2. **Noise due to partial knowledge of $$ x $$**: Even if we observe $$ x $$, our knowledge of the variables influencing $$ y $$ is often incomplete. We might be unaware of all the relevant factors or their interactions. This means the model lacks the necessary information to make precise predictions about $$ y $$, introducing noise into the estimates of $$ \hat{y} $$.

Since we do not know the internal nature of $$ S $$, we treat every source of error as a **single noise source**. We cannot distinguish specific causes, as we only have observable data and not the underlying structure of the system $$ S $$.

<h2 id="data-formalization"><span class="me-2">Formalizing the Units</span><a href="#data-formalization" class="anchor text-muted"></a></h2>

The units $$ x $$ and $$ y $$ can be:

- Real numbers: $$ \mathbb{R} $$;  
- Vectors of dimension $$ d $$: $$ \mathbb{R}^d $$;  
- Categorical variables: $$ \{ \mathcal{Y, G, B} \} $$, which belong to specific categories (e.g., colors);  
- Graphs;

<h3 id="real-numbers"><span class="me-2">Real Numbers and Vectors</span><a href="#real-numbers" class="anchor text-muted"></a></h3>
We like real numbers or vectors of real numbers because we can calculate their **distance**. For example:

- If $$ x \in \mathbb{R} $$ (real numbers), the distance between $$ x_1 $$ and $$ x_2 $$ can be calculated as:
  
  $$  
  |x_1 - x_2|^2  
  $$

- If $$ x \in \mathbb{R}^d $$ (a vector of real numbers of dimension $$ d $$), the distance between $$ x_1 $$ and $$ x_2 $$ is calculated using the norm:
  
  $$  
  \| x_1 - x_2 \|^2  
  $$

<h3 id="categorical-variables"><span class="me-2">Categories</span><a href="#categorical-variables" class="anchor text-muted"></a></h3>

However, for **categories**, a problem arises. Imagine mapping a category like this:

$$  
x \in \{\mathcal{Y}, \mathcal{G}, \mathcal{B}\} \rightarrow \{1, 2, 3\}  
$$

where $$ \mathcal{Y, G, B} $$ represent yellow, green, and blue colors, respectively. What we are implying is that $$ Y $$ is closer to $$ G $$ than to $$ B $$, but this interpretation is incorrect and misleading.  

<blockquote class="prompt-danger">  
Although it might seem natural to assume that colors share some similarities, in the case of categories, colors are merely labels, and any perceived similarity does not reflect actual proximity or association.  
</blockquote>

We need to transform these elements into a representation similar to the other two cases.

To solve this problem, we transform each category element into a vector of variables, where each element is represented by a unique position:

$$
x \in \{ Y, G, B \} \rightarrow 
\left\{
\begin{array}{l}
Y \rightarrow (1, 0, 0) \\
G \rightarrow (0, 1, 0) \\
B \rightarrow (0, 0, 1)
\end{array}
\right\} \in \mathbb{R}^d
$$

This allows us to treat them as vectors of real numbers.

This approach is called **One-Hot Encoding**. Why do we like it? Because it does not introduce a false relationship of order or distance between the categories, which is particularly useful when dealing with pure categorical variables, where each category is independent and there is no hierarchy among the options.

Unlike **categorical variables**, **ordinal variables** (e.g., $$ x \in \{1, 2, 3, 4\} $$) do not require One-Hot Encoding, as there is an inherent notion of discrete distance. In this case, we can treat them as belonging to $$ \mathbb{R} $$. The presence of order and distance allows us to use a direct numerical representation without risking incorrect interpretations.

And what about graphs?

<h3 id="graph"><span class="me-2">Graphs</span><a href="#graph" class="anchor text-muted"></a></h3>

To represent **graphs**, we can use an **adjacency matrix**, which describes the connections between nodes. However, this representation does not include a true notion of geometric distance between nodes or between matrices. The adjacency matrix only tells us which nodes are connected but not how "close" or "distant" they are in a spatial or numerical sense.

We can represent the graph as a unique vector:

![Light mode only](/grafo.png){: .light }  
![Dark mode only](/grafodark.png){: .dark }  

In this representation, each position in the vector contains a binary value: $$ 1 $$ if the connection exists, and $$ 0 $$ if it does not.

$$ D $$ indicates the dimension of the distances considered. For example, $$ D = 1 $$ represents whether a node is present or not in the graph, while $$ D = 2 $$ considers the direct connections between two nodes, and so on.

What’s the problem with this representation?

Assuming $$ n $$ nodes, let’s see how many substructures exist at each dimension:

$$ \hspace{-0.5cm} D = 1 \Rightarrow n $$

$$ D = 2 \Rightarrow \binom{n}{2} $$

$$ \vdots $$

$$ D = p \Rightarrow \binom{n}{p} \approx n^p $$

These represent all the ways to select $$ 1 $$ node from $$ n $$ nodes, $$ 2 $$ nodes from $$ n $$ nodes, $$ p $$ nodes from $$ n $$ nodes, respectively.

Using this approach leads to exponential time complexity, which means it will take exponential time to store such a structure in a computer. Moral of the story: we don’t store it.

<h2 id="computational-problems"><span class="me-2">Classes of Computational Problems</span><a href="#computational-problems" class="anchor text-muted"></a></h2>

![Light mode only](/complex.png){: .light }  
![Dark mode only](/complexdark.png){: .dark }  

**Polynomial** means that if a problem is defined by a number $$ n $$, the time or space required to solve that problem, as $$ n $$ changes, grows at most polynomially.

**Non-polynomial** means that the growth is not polynomial, such as exponential, factorial, or combinatorial.

An example of an **uncomputable problem** is determining whether an infinite *while* loop will terminate.

Machine learning falls into computationally solvable polynomial problems, while deep learning belongs to non-polynomially solvable problems.

Deep learning is an approximation of the non-polynomial case of learning theory, which Kolmogorov proved to be uncomputable.

Thus, we want to learn from the data provided by an unknown system, but we have another constraint: whatever we want to do, we must be able to perform it on a computer that can solve either polynomial or non-polynomial problems, depending on the problem's size.

ChatGPT was born only recently, thanks to two main factors:

1. More powerful computers.  
2. Greater data availability.

Looking back, the journey of artificial intelligence reminds us how theory and practice dance together, even if at different rhythms. The foundations of learning theory and neural networks existed as early as the 1970s, but they were like seeds planted in uncultivated soil: they needed time and technology to sprout and flourish.

Today, with increasingly powerful computers and unimaginable amounts of data just a few decades ago, we finally see that soil becoming fertile.

But our journey has only just begun. The upcoming lessons will take us closer to discovering how to build and refine a *learning machine* capable of learning, adapting, and even predicting something close to the future. Even though, as we’ve seen, it will never be exactly accurate, isn’t it precisely the uncertainty of not having a definitive answer that makes our journey so meaningful?

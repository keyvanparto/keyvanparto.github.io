---
layout: post
title: "Lesson 1: Building a Learning Machine"
description: "An overview of machine learning: predicting the future by learning from the past"
media_subpath: /img/lesson_1
image:
  path: /building_a_learning_machine.png
date: 2024-11-02
math: true
categories: [Machine Learning, en]
tags: [machine-learning, introduction, learning-algorithms, data-science, ai-basics, model-training, ml-theory]     # TAG names should always be lowercase
---

In the real world, there are many complex phenomena that escape our complete understanding. Often, we don’t know exactly how they work internally, but we can observe some input variables and, in certain cases, the final outcomes: these two measures are our data. And the more data we have, the happier we are. <br><br> 
Ultimately, whether it’s about understanding the stock market or our chances of survival, what we humans desire most is to predict the future.

<h2 id="world-phenomena"><span class="me-2">Formalizing World Phenomena</span><a href="#world-phenomena" class="anchor text-muted"></a></h2>

<br><br>

![Light mode only](/sistema.png){: .light }
![Dark mode only](/sistemadark.png){: .dark }
_A highly simplified model of many real complex phenomena_

<br>

We have:

1. **an unknown system**: $$ S $$ represents a complex system whose rules or internal mechanisms are unknown, a kind of “black box.” We don’t know the algorithms, logic, or rules that govern it, and we can’t “look inside” to find out. However, we know that $$ S $$ produces certain observable results.

2. **measurable variables**: $$ x $$ represents the data we can easily collect. These inputs could include observations we already have or can obtain without excessive costs, such as a customer’s transaction history, weather data in an area, or routine medical test results. In other words, $$ x $$ is the set of available, observable data from which we can begin exploring the system.

3. **target variables**: $$ y $$ represents what we want to predict or understand. However, measuring $$ y $$ can often be difficult or costly. $$ y $$ might be a value that will only be available in the future (like the price of a stock a month from now) or something complex and costly to determine at the moment (like the exact wear status of all components in a vehicle). If we wait long enough, sometimes $$ y $$ may become observable — for example, we’ll know which part of a car will break down only when it actually fails.

Thus, $$ x $$ and $$ y $$ represent our historical data.

<blockquote class="prompt-warning">
  <p>It is essential to note that there is no causal relationship between \( x \) and \( y \) (\( x \) doesn’t necessarily generate a certain \( y \)), but rather there is only a <strong>correlation</strong> between them.</p>
</blockquote>

<h2 id="learning-machine"><span class="me-2">Learning Machine</span><a href="#learning-machine" class="anchor text-muted"></a></h2>

Our goal is to build a learning machine that, using historical data (in other words, the past), can make reliable predictions about the future. Given an input $$ x $$, possibly never seen before, we want to obtain an estimate $$ \hat{y} $$ that is as close as possible to the actual value of $$ y $$ from the original system.

![Light mode only](/learningmachine.png){: .light }
![Dark mode only](/learningmachinedark.png){: .dark }
_The closest thing to predicting the future_

In other words, we are trying to predict the future. But when can we actually predict the future?

<blockquote class="prompt-info">
  <p>We can only predict the future if it is similar to the past.</p>
</blockquote>

We need to define *similarity* and what a good approximation between $$ \hat{y} $$ and $$ y $$ means.

But is it possible to predict the future perfectly? Even if we had an oracle providing all the historical data we need?

The answer is no.

Perfect predictions are impossible, and the main reason is **noise**.

<h3 id="noise"><span class="me-2">Noise</span><a href="#noise" class="anchor text-muted"></a></h3>

There are primarily two sources of noise that influence predictions:

1. Noise from **measurement errors**: this type of noise occurs due to inaccuracies in instruments or measurement techniques. Every time we collect data, especially in the real world, there is always an element of error that introduces unwanted variations in observed values.

2. Noise due to **partial knowledge of $$ x $$**: even if we observe $$ x $$, our understanding of the variables that influence $$ y $$ is often incomplete. We may not know all relevant factors or their interactions. This means the model lacks all necessary information to make an accurate prediction of $$ y $$, thus introducing noise into the estimates of $$ \hat{y} $$.

Since we don’t know the internal nature of $$ S $$, we treat each error source as **single noise**. We can’t distinguish specific causes because we only know the observable data, not the underlying structure of the system $$ S $$.

<h2 id="data-formalization"><span class="me-2">Formalizing Units</span><a href="#data-formalization" class="anchor text-muted"></a></h2>

The units $$ x $$ and $$ y $$ can be:

- real numbers: $$ \mathbb{R} $$;
- vectors of dimension $$ d $$ : $$ \mathbb{R}^d $$;
- categorical variables: $$ \{ \mathcal{G, Y, B} \} $$, which belong to a specific category (like colors);
- graphs.

<h3 id="real-numbers"><span class="me-2">Real Numbers and Vectors</span><a href="#real-numbers" class="anchor text-muted"></a></h3>
We like real numbers or vectors of real numbers because we can calculate the **distance** between them. For example:

- If $$ x \in \mathbb{R} $$ (real numbers), the distance between $$ x_1 $$ and $$ x_2 $$ can be calculated as:
  
  $$
  |x_1 - x_2|^2
  $$

- If $$ x \in \mathbb{R}^d $$ (vectors of real numbers with dimension $$ d $$), the distance between $$ x_1 $$ and $$ x_2 $$ is calculated using the norm:
  
  $$
  \| x_1 - x_2 \|^2
  $$

<h3 id="categorical-variables"><span class="me-2">Categories</span><a href="#categorical-variables" class="anchor text-muted"></a></h3>

For **categories**, however, a problem arises. Suppose we map a category in this way:

$$
x \in \{ Y, G, B \} \rightarrow \{ 1, 2, 3 \} $$

This implies that $$ Y $$ is closer to $$ G $$ than to $$ B $$, which is incorrect unless we want to make it so for artistic reasons. Therefore, we transform these elements into a representation similar to the previous cases.

To solve this, we transform each category element into a variable vector, where each element is represented by a unique position:

$$
x \in \{ Y, G, B \} \rightarrow 
\left\{
\begin{array}{l}
Y \rightarrow (1, 0, 0) \\
G \rightarrow (0, 1, 0) \\
B \rightarrow (0, 0, 1)
\end{array}
\right\} \in \mathbb{R}^d
$$

And we can treat them as vectors of real numbers.

This approach is called **One-Hot Encoding**. Why do we like it? Because it doesn’t introduce a false relationship of order or distance between the categories, which is especially useful when handling pure categorical variables, where each category is independent and no hierarchy exists.

Unlike **categorical variables**, **ordinal variables** (e.g., $$ x \in \{1, 2, 3, 4\} $$) don’t require One-Hot Encoding, as they do have a notion of distance, even if discrete; therefore, they can be treated as belonging to $$ \mathbb{R} $$. This ordering and distance allow a direct numeric representation without introducing incorrect interpretations.

And for graphs?

<h3 id="graph"><span class="me-2">Graphs</span><a href="#graph" class="anchor text-muted"></a></h3>

To represent **graphs**, we could use an **adjacency matrix**, describing connections between nodes. However, this representation doesn’t include a real notion of geometric distance between nodes or matrices. The adjacency matrix only tells us which nodes are connected, but not how “close” or “distant” they are in a spatial or numeric sense.

We could represent the graph with a single vector like this:

![Light mode only](/grafo.png){: .light }
![Dark mode only](/grafodark.png){: .dark }

In this representation, each vector position contains a binary value: $$ 1 $$ if a connection is present, and $$ 0 $$ if it is not.

$$ D $$ indicates the dimension of the considered distances. For example, $$ D = 1 $$ represents whether a node is present in the graph, while $$ D = 2 $$ considers direct connections between two nodes, and so on.

What’s the problem with this representation?

Assuming $$ n $$ nodes, let’s see how many substructures exist in each dimension.<br><br>

$$ \hspace{-0.5cm} D = 1 \Rightarrow n $$

$$ D = 2 \Rightarrow \binom{n}{2} $$
  
$$ \vdots $$

$$ D = p \Rightarrow \binom{n}{p} \approx n^p $$

This is simply the number of ways to pick $$ 1 $$ node out of $$ n $$ nodes, $$ 2 $$ nodes out of $$ n $$ nodes, and so on for $$ p $$ nodes out of $$ n $$ nodes.

Following this method, we end up with exponential time, meaning it would take exponential time to store such a structure in a computer. Moral of the story: we don’t store it.

<h2 id="computational-problems"><span class="me-2">Classes of Computational Problems</span><a href="#computational-problems" class="anchor text-muted"></a></h2>

![Light mode only](/complex.png){: .light }
![Dark mode only](/complexdark.png){: .dark }

**Polynomial** means that if you have a problem defined by a number $$ n $$, the time or space required to solve it, as $$ n $$ changes, grows at most polynomially.

**Non-polynomial** means that the growth is not polynomial, e.g., exponential, factorial, or combinatorial.

An example of a **non-computable** problem is determining whether an infinite *while* loop can terminate.

Machine learning falls into the category of polynomially computable problems, while deep learning often falls into non-polynomially computable problems.

Deep learning is an approximation of the non-polynomial case in learning theory, which Kolmogorov proved to be non-computable.

So, we aim to learn from data provided by an unknown system, but we have one more constraint: anything we want to do must be doable on a computer that can solve polynomial or non-polynomial problems, depending on the problem’s size.

ChatGPT, in fact, was only born recently due to two main factors:

1. more powerful computers.
2. greater availability of data.

Looking back, the journey of artificial intelligence reminds us how theory and practice dance together, albeit at different rhythms. The foundations of learning theory and neural networks existed as far back as the ’70s, but they were like seeds planted in still-unfertile soil: they needed time and technology to grow and bloom.

Today, with increasingly powerful computers and amounts of data unimaginable until a few decades ago, we’re finally seeing that soil become fertile.

But our journey is just beginning. The next lessons will bring us closer to discovering how to build and refine a *learning machine* capable of learning, adapting, and perhaps, who knows, predicting a possible future. And, as we’ve seen, although it will never be perfect, isn’t it perhaps the uncertainty, the lack of a definitive answer, that makes our journey so meaningful?

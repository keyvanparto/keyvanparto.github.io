---
layout: post
title: "Lezione 1: Costruire una Macchina di Apprendimento"
description: "Una panoramica sul machine learning: prevedere il futuro imparando dal passato"
media_subpath: /img/lesson_1
image:
  path: /building_a_learning_machine.png
date: 2024-11-01
math: true
categories: [Machine Learning, ita]
tags: [machine-learning, introduction, learning-algorithms, data-science, ai-basics, model-training, ml-theory]     # TAG names should always be lowercase
---


Nel mondo reale ci sono numerosi fenomeni complessi che sfuggono alla nostra comprensione dettagliata. Spesso non sappiamo esattamente come funzionino al loro interno, ma possiamo osservarne alcune variabili di input e, in certi casi, i risultati finali: queste due misure sono i nostri dati. E più ne abbiamo più siamo contenti. <br><br>
In ultima istanza, che si tratti di conoscere il mercato finanziario o le nostre probabilità di sopravvivenza, quello che noi esseri umani desideriamo è riuscire a prevedere il futuro.

<h2 id="world-phenomena"><span class="me-2">Formalizzazione dei fenomeni del mondo</span><a href="#world-phenomena" class="anchor text-muted"></a></h2>

<br><br>

![Light mode only](/sistema.png){: .light }
![Dark mode only](/sistemadark.png){: .dark }
_Un modello estremamente semplificato di molti fenomeni complessi reali_

<br>

Abbiamo quindi:


1. **un sistema sconosciuto**: $$ S $$ è un sistema complesso di cui non conosciamo le regole o i meccanismi interni, una sorta di "scatola nera". Non sappiamo esattamente quali algoritmi, logiche o regole lo governino, e non abbiamo modo di "guardare dentro" per scoprirlo. Tuttavia, sappiamo che $$ S $$ produce certi risultati osservabili.

2. **variabili misurabili**: $$ x $$ rappresenta i dati che possiamo raccogliere facilmente. Questi input possono includere osservazioni che già possediamo o che possiamo ottenere senza costi eccessivi, come la cronologia delle transazioni di un cliente, i dati meteorologici di una zona o i risultati di esami medici di routine. In altre parole, $$ x $$ è l'insieme dei dati disponibili e osservabili da cui possiamo partire per esplorare il sistema.

3. **variabili obiettivo**: $$ y $$ rappresenta ciò che vorremmo predire o comprendere. Spesso, tuttavia, misurare $$ y $$ può essere difficile o costoso. $$ y $$ potrebbe essere un valore che ci sarà disponibile solo in futuro (come il prezzo di un'azione fra un mese) oppure qualcosa che risulta complesso e oneroso da determinare al momento (come lo stato esatto di usura di tutte le componenti di un veicolo). Se aspettiamo abbastanza, a volte $$ y $$ può diventare osservabile — ad esempio, sapremo quale parte di un’auto si guasterà quando effettivamente si romperà.

$$ x $$ e $$ y $$ rappresentano quindi i nostri dati storici.

<blockquote class="prompt-warning">
  <p>Ѐ di fondamentale importanza notare che fra \( x \) e \( y \) non c'è alcuna relazione di causalità (\( x \) non genera necessariamente un certo \( y \)), ma fra di loro c'è solo un legame di <strong>correlazione</strong>.</p>
</blockquote>

<h2 id="learning-machine"><span class="me-2">Learning Machine</span><a href="#learning-machine" class="anchor text-muted"></a></h2>

Il nostro obiettivo è costruire una learning machine che, utilizzando gli historical data (ovvero il passato), sia in grado di fare previsioni affidabili sul futuro. Dato un input $$ x $$, magari mai visto prima, vogliamo ottenere una stima $$ \hat{y} $$ che sia il più possibile vicina al valore reale di $$ y $$ del sistema originale. 


![Light mode only](/learningmachine.png){: .light }
![Dark mode only](/learningmachinedark.png){: .dark }
_Quanto di più simile c'è a predire il futuro_



In altre parole, stiamo cercando di predire il futuro. Ma quando sappiamo predire il futuro?

<blockquote class="prompt-info">
  <p>Sappiamo prevedere il futuro solo ed esclusivamente quando è simile al passato.</p>
</blockquote>


Dobbiamo definire *simile* e cosa significa buona approssimazione fra $$ \hat{y} $$ e $$ y $$ .

Ma è possibile prevedere esattamente il futuro? Anche se avessimo un oracolo che ci fornisce tutti gli historical data di cui abbiamo bisogno?

La risposta è no.

Non è possibile fare previsioni perfette, e il motivo principale è il **rumore**.

<h3 id="noise"><span class="me-2">Rumore</span><a href="#noise" class="anchor text-muted"></a></h3>

Ci sono principalmente due fonti di rumore che influenzano le previsioni:

1. Rumore dovuto ad **errori di misurazione**: questo tipo di rumore si verifica a causa di imprecisioni negli strumenti o nelle tecniche di misurazione. Ogni volta che raccogliamo dati, specialmente nel mondo reale, c’è sempre una componente di errore che introduce variazioni indesiderate nei valori osservati.

2. Rumore dovuto alla **conoscenza parziale di $$ x $$**: anche se osserviamo $$ x $$, la nostra conoscenza delle variabili che influenzano $$ y $$ è spesso incompleta. Potremmo non essere a conoscenza di tutti i fattori rilevanti o delle loro interazioni. Questo significa che il modello non dispone di tutte le informazioni necessarie per fare una previsione precisa su $$ y $$, introducendo così rumore nelle stime di $$ \hat{y} $$.

Tuttavia, poiché non conosciamo la natura interna di $$ S $$, trattiamo ogni fonte di errore come **rumore unico**. Non abbiamo modo di distinguere le cause specifiche, poiché conosciamo solo i dati osservabili e non la struttura del sistema sottostante $$ S $$.

<h2 id="data-formalization"><span class="me-2">Formalizzazione delle unità</span><a href="#data-formalization" class="anchor text-muted"></a></h2>

Le unità $$ x $$ e $$ y $$ possono essere:

- numeri reali: $$ \mathbb{R} $$;
- vettori di dimensione $$ d $$ : $$ \mathbb{R}^d $$;
- categorical variables: $$ \{ \mathcal{G, Y, B} \} $$: possono cioè appartenere ad una categoria specifica (ad esempio colori);
- grafi;

<h3 id="real-numbers"><span class="me-2">Numeri reali e vettori</span><a href="#real-numbers" class="anchor text-muted"></a></h3>
A noi piacciono i numeri reali o i vettori di numeri reali perché possiamo calcolarne la **distanza**. Ad esempio:

- Se $$ x \in \mathbb{R} $$ (numeri reali), la distanza tra $$ x_1 $$ e $$ x_2 $$ può essere calcolata come:
  
  $$
  |x_1 - x_2|^2
  $$

- Se $$ x \in \mathbb{R}^d $$ (vettori di numeri reali di dimensione $$ d $$), la distanza tra $$ x_1 $$ e $$ x_2 $$ è calcolata utilizzando la norma:
  
  $$
  \| x_1 - x_2 \|^2
  $$

<h3 id="categorical-variables"><span class="me-2">Categorie</span><a href="#categorical-variables" class="anchor text-muted"></a></h3>

Tuttavia, per le **categorie** sorge un problema. Se ad esempio decido di mappare una categoria in questo modo:

$$
x \in \{ Y, G, B \} \rightarrow \{ 1, 2, 3 \} $$

quello che sto dicendo è che $$ Y $$ è più vicino a $$ G $$ di quanto non lo sia a $$ B $$, ma questa interpretazione è errata e non veritiera (a meno che non vogliate fare gli artisti). Dobbiamo quindi trasformare questi elementi in una rappresentazione simile agli altri due casi.

Per risolvere questo problema, trasformiamo ogni elemento della categoria in un vettore di variabili, in cui ogni elemento è rappresentato da una posizione unica: 

$$
x \in \{ Y, G, B \} \rightarrow 
\left\{
\begin{array}{l}
Y \rightarrow (1, 0, 0) \\
G \rightarrow (0, 1, 0) \\
B \rightarrow (0, 0, 1)
\end{array}
\right\} \in \mathbb{R}^d
$$

E li possiamo trattare come vettori di numeri reali.

Questo approccio si chiama **One-Hot Encoding**. Perché ci piace? Perché non introduce una falsa relazione di ordine o distanza tra le categorie, il che è particolarmente utile quando trattiamo variabili categoriche pure, in cui ogni categoria è indipendente e non esiste una gerarchia tra le opzioni.

A differenza delle **categorical variables**, le **ordinal variables** (ad esempio, $$ x \in \{1, 2, 3, 4\} $$) non necessitano del One-Hot Encoding, perché in questo caso esiste una nozione di distanza, anche se discreta; quindi possiamo trattarle come appartenenti a $$ \mathbb{R} $$. La presenza di un ordine e una distanza consente di usare una rappresentazione numerica diretta senza rischiare di introdurre interpretazioni errate.

E per i grafi?

<h3 id="graph"><span class="me-2">Grafi</span><a href="#graph" class="anchor text-muted"></a></h3>

Per rappresentare i **grafi**, potremmo utilizzare una **matrice di adiacenza**, che descrive le connessioni tra i nodi. Tuttavia, questa rappresentazione non include una vera e propria nozione di distanza geometrica tra nodi o tra matrici. La matrice di adiacenza ci indica solo quali nodi sono collegati, ma non come sono "vicini" o "distanti" in un senso spaziale o numerico.

Potrei rappresentare il grafo così tramite un vettore unico:

![Light mode only](/grafo.png){: .light }
![Dark mode only](/grafodark.png){: .dark }

In questa rappresentazione ogni posizione del vettore contiene un valore binario: $$ 1 $$ se il collegamento è verificato, mentre $$ 0 $$ se non è verificato.

$$ D $$ indica la dimensione delle distanze considerate. Ad esempio, $$ D = 1 $$ rappresenta se il nodo è presente o meno nel grafo, mentre $$ D = 2 $$ considera le connessioni dirette tra due nodi e così via.

Qual è il problema di questa rappresentazione?

Supponendo $$ n $$ nodi andiamo a vedere quante sottostrutture ci sono in ogni dimensione.<br><br>


$$ \hspace{-0.5cm} D = 1 \Rightarrow n $$

$$ D = 2 \Rightarrow \binom{n}{2} $$
  
$$ \vdots $$

$$ D = p \Rightarrow \binom{n}{p} \approx n^p $$

che sono tutti i modi per prendere rispettivamente $$ 1 $$ nodo fra $$ n $$ nodi, $$ 2 $$ nodi fra $$ n $$ nodi, $$ p $$ nodi fra $$ n $$ nodi.

Procedendo in questa maniera arriviamo quindi ad un tempo esponenziale e mi ci vorrà quindi un tempo esponenziale per memorizzare una struttura del genere in un computer. Morale della favola: non lo memorizzo.

<h2 id="computational-problems"><span class="me-2">Classi di problemi computazionali</span><a href="#computational-problems" class="anchor text-muted"></a></h2>

![Light mode only](/complex.png){: .light }
![Dark mode only](/complexdark.png){: .dark }

**Polinomiale** significa che, se hai un problema definito da un numero $$ n $$, il tempo o lo spazio richiesto per risolvere quel problema, al variare di $$ n $$, cresce al massimo polinomialmente.

**Non polinomiale** significa che la crescita è non polinomiale, ad esempio, esponenziale, fattoriale, o combinatoria. 

Un esempio di problema **non computabile** è determinare se un ciclo *while* infinito possa terminare o meno.

Il machine learning ricade nei problemi computabili polinomialmente, mentre il deep learning ricade nei problemi computabili non polinomialmente.

Il deep learning è un'approssimazione del caso non polinomiale della teoria dell'apprendimento, che è stata dimostrata non computabile da Kolmogorov. 

Quindi noi vorremmo imparare dai dati che sono forniti da un sistema non conosciuto, ma abbiamo un altro vincolo: qualunque cosa vogliamo fare, dobbiamo poterla fare su un computer che può risolvere problemi polinomiali o non polinomiali, a seconda della dimensione del problema. 

ChatGPT infatti è nato soltanto recentemente grazie a due fattori principali:

1. computer più potenti.
2. maggiore disponibilità di dati.

Guardando indietro, la strada percorsa dall’intelligenza artificiale ci ricorda quanto la teoria e la pratica danzino insieme, anche se a ritmi diversi. I fondamenti della teoria dell’apprendimento e delle reti neurali esistevano già dagli anni '70, ma erano come semi piantati in un terreno ancora incolto: avevano bisogno di tempo e di tecnologia per germogliare e fiorire.

Oggi, con computer sempre più potenti e quantità di dati impensabili fino a qualche decennio fa, vediamo finalmente quel terreno diventare fertile. 

Ma il nostro viaggio è appena cominciato. Le prossime lezioni ci porteranno sempre più vicino a scoprire come costruire e affinare una *learning machine* in grado di apprendere, adattarsi e, forse chissà, prevedere un futuro possibile. Anche se, come abbiamo visto, non sarà mai come lo immaginiamo, non è forse proprio l'incertezza di non poter avere una risposta univocamente esatta che rende il nostro percorso così significativo?